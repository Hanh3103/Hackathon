{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANsfkXx-rdYV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "\n",
    "def save_model(model, checkpointfolder, checkpointname):\n",
    "    model.save_weights('./' + checkpointfolder + '/' + checkpointname)\n",
    "\n",
    "\n",
    "def load_model(label_count, checkpointfolder, checkpointname):\n",
    "    model = create_model(label_count)\n",
    "    model.load_weights('./' + checkpointfolder + '/' + checkpointname)\n",
    "    return model\n",
    "\n",
    "def eval_model_adv():\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Accuracy: %.3f' % acc)\n",
    "\n",
    "    neg_y_test = []\n",
    "    neg_X_test = []\n",
    "\n",
    "    pos_y_test = []\n",
    "    pos_X_test = []\n",
    "\n",
    "    for idx, row in enumerate(y_test):\n",
    "      if(y_test[idx] == 0):\n",
    "        neg_y_test.append(y_test[idx])\n",
    "        neg_X_test.append(X_test[idx])\n",
    "        #print(y_test[idx])\n",
    "        #print(X_test[idx])\n",
    "        #print(model(X_test[idx].reshape(1, 15730)))\n",
    "      else:\n",
    "        pos_y_test.append(y_test[idx])\n",
    "        pos_X_test.append(X_test[idx])\n",
    "        #print(y_test[idx])\n",
    "        #print(X_test[idx])\n",
    "        #print(model(X_test[idx].reshape(1, 15730)))\n",
    "\n",
    "    neg_y_test = np.array(neg_y_test)\n",
    "    neg_X_test = np.array(neg_X_test)\n",
    "    loss, acc = model.evaluate(neg_X_test, neg_y_test, verbose=1)\n",
    "    print('Test Accuracy (only negatives): %.3f' % acc)\n",
    "\n",
    "    pos_y_test = np.array(pos_y_test)\n",
    "    pos_X_test = np.array(pos_X_test)\n",
    "    loss, acc = model.evaluate(pos_X_test, pos_y_test, verbose=1)\n",
    "    print('Test Accuracy (only positives): %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def load_data(type):\n",
    "    df_ = pd.read_csv('/content/drive/MyDrive/HackathonData/' + type)\n",
    "    # split into input and output columns\n",
    "    inputvalues = df_.drop(['label', 'sample_ID'], axis=1)\n",
    "    outputvalues = df_['label']\n",
    "    # outputvalues = y_vec\n",
    "    X, y = inputvalues.values, outputvalues.values\n",
    "    \n",
    "    # example of random oversampling to balance the class distribution\n",
    "    from collections import Counter\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    # define oversampling strategy\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    # fit and apply the transform\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    # summarize class distribution\n",
    "    print(Counter(y))\n",
    "\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    # split into train and test datasets\n",
    "    x_train_, x_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.3, random_state=1234) # seed\n",
    "    #x_train_, x_val_, y_train_, y_val_ = train_test_split(x_train_, y_train_, test_size=0.15, random_state=1234)\n",
    "    x_val_ = []\n",
    "    y_val_ = []\n",
    "    print(x_train_.shape, x_test_.shape, y_train_.shape, y_test_.shape)\n",
    "    # determine the number of input features\n",
    "    n_features_ = x_train_.shape[1]\n",
    "    return df_, x_train_, x_val_, x_test_, y_train_, y_val_, y_test_, n_features_, 1"
   ],
   "metadata": {
    "id": "fXmr3JWqrt9q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model(label_count):\n",
    "    # define model\n",
    "    activation = 'relu'\n",
    "    initializer = tf.keras.initializers.he_normal(seed=1234)\n",
    "    model_ = Sequential()\n",
    "    model_.add(Dense(170, activation=activation, kernel_initializer=initializer, input_shape=(n_features,)))\n",
    "    model_.add(Dense(70, activation=activation, kernel_initializer=initializer))\n",
    "    #model_.add(Dense(13500, activation=activation, kernel_initializer=initializer))\n",
    "    #model_.add(Dense(12000, activation=activation, kernel_initializer=initializer))\n",
    "    #model_.add(Dense(7000, activation=activation, kernel_initializer=initializer))\n",
    "    #model_.add(Dense(3000, activation=activation, kernel_initializer=initializer))\n",
    "    #model_.add(Dense(1, activation=activation, kernel_initializer=initializer))\n",
    "    #model_.add(Dense(200, activation=activation, kernel_initializer=initializer))\n",
    "    #model_.add(Dense(50, activation=activation, kernel_initializer=initializer))\n",
    "    #model_.add(Dense(10, activation=activation, kernel_initializer=initializer))\n",
    "    #model_.add(Dense(4, activation=activation, kernel_initializer=initializer))\n",
    "    model_.add(Dense(label_count, activation=\"sigmoid\"))\n",
    "    # compile the model\n",
    "    model_.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model_\n",
    "\n",
    "\n",
    "def fit_model(model, X_train, y_train):\n",
    "    # fit the model\n",
    "    #callbacks_list = [PlotLearning()]\n",
    "    model.fit(X_train, y_train, epochs=42, batch_size=744, verbose=0) #callbacks=callbacks_list\n",
    "\n",
    "\n",
    "print('_____ ' + 'SpeciesT2D_train' + ' _____')\n",
    "df, X_train, x_val, X_test, y_train, y_val, y_test, n_features, label_count = load_data('T2D/SpeciesT2D_train.csv')\n",
    "model = create_model(label_count=label_count)\n",
    "fit_model(model, X_train, y_train)\n",
    "save_model(model, \"SpeciesT2D\", \"1x70_42_500_relu\")\n",
    "#model = load_model(label_count, \"SpeciesT2D\", \"1x70_42_500_relu\")\n",
    "eval_model_adv()\n",
    "gc.collect()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J3ospRrCr0fz",
    "outputId": "760fa05b-e916-49c3-ca9a-73b01bf728f0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({1: 532, 0: 532})\n",
      "(744, 15730) (320, 15730) (744,) (320,)\n",
      "Epoch 1/42\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 26.7875 - accuracy: 0.4637\n",
      "Epoch 2/42\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 35.3380 - accuracy: 0.5282\n",
      "Epoch 3/42\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 19.9074 - accuracy: 0.5524\n",
      "Epoch 4/42\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.1937 - accuracy: 0.7245\n",
      "Epoch 5/42\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.0637 - accuracy: 0.7433\n",
      "Epoch 6/42\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.9394 - accuracy: 0.6626\n",
      "Epoch 7/42\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.8139 - accuracy: 0.7339\n",
      "Epoch 8/42\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.4644 - accuracy: 0.8616\n",
      "Epoch 9/42\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5518 - accuracy: 0.9207\n",
      "Epoch 10/42\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6450 - accuracy: 0.9046\n",
      "Epoch 11/42\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8465 - accuracy: 0.8925\n",
      "Epoch 12/42\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7430 - accuracy: 0.8965\n",
      "Epoch 13/42\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4237 - accuracy: 0.9234\n",
      "Epoch 14/42\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1815 - accuracy: 0.9677\n",
      "Epoch 15/42\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0755 - accuracy: 0.9839\n",
      "Epoch 16/42\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0473 - accuracy: 0.9866\n",
      "Epoch 17/42\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0551 - accuracy: 0.9785\n",
      "Epoch 18/42\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0626 - accuracy: 0.9798\n",
      "Epoch 19/42\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0545 - accuracy: 0.9825\n",
      "Epoch 20/42\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0362 - accuracy: 0.9892\n",
      "Epoch 21/42\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0183 - accuracy: 0.9946\n",
      "Epoch 22/42\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0091 - accuracy: 0.9987\n",
      "Epoch 23/42\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0048 - accuracy: 0.9987\n",
      "Epoch 24/42\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 25/42\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 26/42\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 27/42\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 28/42\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 29/42\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 30/42\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 31/42\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9.3198e-04 - accuracy: 1.0000\n",
      "Epoch 32/42\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.8461e-04 - accuracy: 1.0000\n",
      "Epoch 33/42\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.7520e-04 - accuracy: 1.0000\n",
      "Epoch 34/42\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.8923e-04 - accuracy: 1.0000\n",
      "Epoch 35/42\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.1994e-04 - accuracy: 1.0000\n",
      "Epoch 36/42\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.6201e-04 - accuracy: 1.0000\n",
      "Epoch 37/42\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.1332e-04 - accuracy: 1.0000\n",
      "Epoch 38/42\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.7367e-04 - accuracy: 1.0000\n",
      "Epoch 39/42\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.4239e-04 - accuracy: 1.0000\n",
      "Epoch 40/42\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1686e-04 - accuracy: 1.0000\n",
      "Epoch 41/42\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.9565e-04 - accuracy: 1.0000\n",
      "Epoch 42/42\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.7731e-04 - accuracy: 1.0000\n",
      "Test Accuracy: 0.534\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.0944 - accuracy: 0.4615\n",
      "Test Accuracy (only negatives): 0.462\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5.3189 - accuracy: 0.5932\n",
      "Test Accuracy (only positives): 0.593\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3832"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('_____ ' + 'SpeciesIBD_train' + ' _____')\n",
    "df, X_train, x_val, X_test, y_train, y_val, y_test, n_features, label_count = load_data('IBD/SpeciesIBD_train.csv')\n",
    "model = create_model(label_count=label_count)\n",
    "fit_model(model, X_train, y_train)\n",
    "#save_model(model, \"SpeciesIBD\", \"1x70_42_500_relu\")\n",
    "#model = load_model(label_count, \"SpeciesIBD\", \"1x70_42_500_relu\")\n",
    "eval_model_adv()\n",
    "gc.collect()\n",
    "\n",
    "print('_____ ' + 'SpeciesCAD_train' + ' _____')\n",
    "df, X_train, x_val, X_test, y_train, y_val, y_test, n_features, label_count = load_data('CAD/SpeciesCAD_train.csv')\n",
    "model = create_model(label_count=label_count)\n",
    "fit_model(model, X_train, y_train)\n",
    "#save_model(model, \"SpeciesCAD\", \"1x70_42_500_relu\")\n",
    "#model = load_model(label_count, \"SpeciesCAD\", \"1x70_42_500_relu\")\n",
    "eval_model_adv()\n",
    "gc.collect()\n",
    "\n",
    "print('_____ ' + 'SpeciesCKD_train' + ' _____')\n",
    "df, X_train, x_val, X_test, y_train, y_val, y_test, n_features, label_count = load_data('CKD/SpeciesCKD_train.csv')\n",
    "model = create_model(label_count=label_count)\n",
    "fit_model(model, X_train, y_train)\n",
    "#save_model(model, \"SpeciesCKD\", \"1x70_42_500_relu\")\n",
    "#model = load_model(label_count, \"SpeciesCKD\", \"1x70_42_500_relu\")\n",
    "eval_model_adv()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
